{"cells":[{"cell_type":"markdown","metadata":{"id":"OJXAGHnx7BzN"},"source":["# **SVM Practive - Answer**\n","\n","Aug 21, 2024\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vg8KFioM7HOI"},"source":["## **1. Bài toán**"]},{"cell_type":"markdown","metadata":{"id":"Nt1Zu8N67JV8"},"source":["**Phân loại văn bản sử dụng SVM**"]},{"cell_type":"markdown","metadata":{"id":"tWSMH92o7LsA"},"source":["***Mục tiêu:***\n","\n","\n","*   Xây dựng được mô hình SVM sử dụng thư viện sklearn.\n","*   Ứng dụng và hiểu cách áp dụng mô hình SVM vào giải quyết bài toán thực tế (*ví dụ: phân loại văn bản*).\n","*   Sử dụng độ đo Accuracy để đánh giá chất lượng mô hình.\n","\n","***Vấn đề:***\n","*   Có một tập các văn bản dạng text không có nhãn, làm sao để biết văn bản này thuộc về thể loại nào, pháp luật, đời sống, văn học, thể thao,…\n","\n","***Dữ liệu:***\n","*   Tập các văn bản và nhãn tương ứng của từng văn bản trong một khoảng thời gian.\n","*   Tập các nhãn - 10 nhãn văn bản:\n","    \n","> Giải trí, Khoa học - Công nghệ, Kinh tế, Pháp luật, Sức khỏe, Thể thao, Thời sự, Tin khác, Độc giả, Đời sống - Xã hội.\n","\n","***Ví dụ văn bản nhãn thể thao:***\n","    \n","> \"Dân_trí Real Madrid đã dẫn trước trong cả trận đấu , nhưng họ vẫn phải chấp_nhận bị Dortmund cầm hòa 2-2 ở Bernabeu . Real Madrid chấp_nhận đứng thứ_hai ở bảng F Champions League ...\"\n","\n","***Bài toán: Phân loại***\n","\n","\n","*   Input: n vector mã hóa của các văn bản - ma trận $X = [x_1, x_2, ... x_n]$\n","*   Output: nhãn $y$ là 1 trong 10 nhãn trên\n"]},{"cell_type":"markdown","metadata":{"id":"5vqcYBy07UX0"},"source":["## **2. Import các thư viện cần thiết, cài thêm một số thư viện chưa sẵn có**"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"axH6PFLa6KHJ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyvi\n","  Downloading pyvi-0.1.1-py2.py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: scikit-learn in c:\\users\\baotg2\\appdata\\local\\anaconda3\\lib\\site-packages (from pyvi) (1.4.2)\n","Collecting sklearn-crfsuite (from pyvi)\n","  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\n","Requirement already satisfied: numpy>=1.19.5 in c:\\users\\baotg2\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn->pyvi) (1.26.4)\n","Requirement already satisfied: scipy>=1.6.0 in c:\\users\\baotg2\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn->pyvi) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in c:\\users\\baotg2\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn->pyvi) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\baotg2\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn->pyvi) (2.2.0)\n","Collecting python-crfsuite>=0.9.7 (from sklearn-crfsuite->pyvi)\n","  Downloading python_crfsuite-0.9.10-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n","Requirement already satisfied: tabulate>=0.4.2 in c:\\users\\baotg2\\appdata\\local\\anaconda3\\lib\\site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n","Requirement already satisfied: tqdm>=2.0 in c:\\users\\baotg2\\appdata\\local\\anaconda3\\lib\\site-packages (from sklearn-crfsuite->pyvi) (4.66.4)\n","Requirement already satisfied: colorama in c:\\users\\baotg2\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>=2.0->sklearn-crfsuite->pyvi) (0.4.6)\n","Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n","   ---------------------------------------- 0.0/8.5 MB ? eta -:--:--\n","   ---------------------------------------- 0.1/8.5 MB 2.9 MB/s eta 0:00:03\n","   -- ------------------------------------- 0.5/8.5 MB 5.6 MB/s eta 0:00:02\n","   ----- ---------------------------------- 1.1/8.5 MB 9.0 MB/s eta 0:00:01\n","   --------- ------------------------------ 2.0/8.5 MB 11.5 MB/s eta 0:00:01\n","   --------------- ------------------------ 3.2/8.5 MB 14.4 MB/s eta 0:00:01\n","   --------------------- ------------------ 4.5/8.5 MB 17.8 MB/s eta 0:00:01\n","   -------------------------- ------------- 5.7/8.5 MB 19.1 MB/s eta 0:00:01\n","   --------------------------------- ------ 7.2/8.5 MB 20.8 MB/s eta 0:00:01\n","   ---------------------------------------  8.4/8.5 MB 21.6 MB/s eta 0:00:01\n","   ---------------------------------------- 8.5/8.5 MB 20.0 MB/s eta 0:00:00\n","Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n","Downloading python_crfsuite-0.9.10-cp312-cp312-win_amd64.whl (154 kB)\n","   ---------------------------------------- 0.0/154.7 kB ? eta -:--:--\n","   ---------------------------------------- 154.7/154.7 kB 9.0 MB/s eta 0:00:00\n","Installing collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n","Successfully installed python-crfsuite-0.9.10 pyvi-0.1.1 sklearn-crfsuite-0.5.0\n"]}],"source":["# Cài đặt thư viện xử lý ngôn ngữ cho tiếng Việt!\n","!pip install pyvi"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"OCP8lV8j7cFT"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.model_selection import learning_curve\n","\n","from sklearn.datasets import load_files\n","from pyvi import ViTokenizer  # thư viện tách từ Tiếng Việt\n","\n","from sklearn import svm\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import accuracy_score\n","\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"TGJ3D0jE7l4w"},"source":["## **3. Load dữ liệu từ thư mục đã crawl từ trước**"]},{"cell_type":"markdown","metadata":{"id":"f8fMaY5w7n-O"},"source":["Cấu trúc thư mục như sau:\n","- `data/news_1135/`\n","    - `Kinh tế/`\n","        - `bài báo 1.txt`\n","        - `bài báo 2.txt`\n","    - `Pháp luật/`\n","        - `bài báo 3.txt`\n","        - `bài báo 4.txt`"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"39GRElXz7x8D"},"outputs":[{"name":"stdout","output_type":"stream","text":["10 files đầu:\n","data/news_1135/Tin khác\\0218e1df21ce358b9c6485176a48f1fcaeedef67.txt\n","data/news_1135/Khoa học - Công nghệ\\bf9889f5f2ffd6c92fa877d35ef0ef5f34f0666d.txt\n","data/news_1135/Tin khác\\d74aab054ffe9f8661df13bc52b438b48a63fe48.txt\n","data/news_1135/Đời sống - Xã hội\\127dbc6ef0942abdafb973f08177bfc7a20dec84.txt\n","data/news_1135/Sức khỏe\\1e040b866160284a0c17adda24fce76a89a6a18a.txt\n","data/news_1135/Thể thao\\a663ffdc3ceea4adde0056650ee5639b606fa0ff.txt\n","data/news_1135/Sức khỏe\\796cdde1c2b062e43e414d1d6439ee23a69b16bd.txt\n","data/news_1135/Đời sống - Xã hội\\3e6e98d7d816a703ba84e8fefc9b3f3fc2853781.txt\n","data/news_1135/Thể thao\\e72837ae1012b4f1caa841c3000cdc8c1cf176e1.txt\n","data/news_1135/Pháp luật\\7d5b1facfbf8ab3186f17d4cb3c59e7f7b523f7e.txt\n","\n","\n","Tổng số files: 1135\n","Danh sách nhãn và id tương ứng:  [(0, 'Giải trí'), (1, 'Khoa học - Công nghệ'), (2, 'Kinh tế'), (3, 'Pháp luật'), (4, 'Sức khỏe'), (5, 'Thể thao'), (6, 'Thời sự'), (7, 'Tin khác'), (8, 'Độc giả'), (9, 'Đời sống - Xã hội')]\n"]}],"source":["data_train = load_files(container_path=\"data/news_1135/\", encoding=\"utf-8\")\n","### bài tập ###\n","# yêu cầu: In ra các kết quả sau:\n","#    - Tên 10 file dữ liệu đầu.\n","#    - Tổng số file dữ liệu.\n","#    - Danh sách nhãn và id tương ứng.\n","# gợi ý: tự làm\n","###############\n","# code\n","print(\"10 files đầu:\")\n","print(\"\\n\".join(data_train.filenames[:10]))\n","print(\"\\n\")\n","print(\"Tổng số files: {}\".format(len(data_train.filenames)))\n","print(\"Danh sách nhãn và id tương ứng: \", [(idx, name) for idx, name in enumerate(data_train.target_names)])\n","\n","\n","###############"]},{"cell_type":"markdown","metadata":{"id":"GMwK0Wr5FhQK"},"source":["## **4. Tiền xử lý dữ liệu đưa dữ liệu từ dạng text về dạng ma trận**"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"40NyJeQ8Fjp3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Danh sách 10 từ dừng đầu tiên (từ không mang ý nghĩa phân loại):  []\n","\n","10 từ đầu tiên trong từ điển:\n","1 :  ('dân_trí', 7104)\n","2 :  ('sở', 18418)\n","3 :  ('gd', 7923)\n","4 :  ('đt', 23960)\n","5 :  ('tỉnh', 21513)\n","6 :  ('gia_lai', 8010)\n","7 :  ('vừa', 22753)\n","8 :  ('ra', 16802)\n","9 :  ('văn_bản', 22471)\n","10 :  ('số', 18375)\n"]}],"source":["### bài tập ###\n","# yêu cầu: Tiền xử lý dữ liệu text về dạng ma trận, sử dụng TF-IDF.\n","# gợi ý: tương tự bài thực hành về NaiveBayes.\n","###############\n","# code\n","# Load dữ liệu các stopwords\n","with open(\"data/vietnamese-stopwords.txt\", encoding=\"utf8\") as f:\n","    stopwords = f.readlines()\n","stopwords = [x.strip().replace(\" \", \"_\") for x in stopwords]\n","print(\"Danh sách 10 từ dừng đầu tiên (từ không mang ý nghĩa phân loại): \", stopwords[:10])\n","print()\n","# Transforming data\n","# Chuyển hoá dữ liệu text về dạng vector TF-IDF\n","#   - loại bỏ từ dừng\n","#   - sinh từ điển\n","module_count_vector = CountVectorizer(stop_words=stopwords)\n","model_rf_preprocess = Pipeline(\n","    [\n","        (\"vect\", module_count_vector),\n","        (\"tfidf\", TfidfTransformer()),\n","    ]\n",")\n","# Hàm thực hiện chuyển đổi dữ liệu text thành dữ liệu số dạng ma trận\n","# Input: Dữ liệu 2 chiều dạng numpy.array, mảng nhãn id dạng numpy.array\n","\n","# Tiền xử lý với Bag of words\n","data_bow = module_count_vector.fit_transform(data_train.data, data_train.target)\n","\n","# Tiền xử lý với TF-IDF\n","data_tfidf = model_rf_preprocess.fit_transform(data_train.data, data_train.target)\n","###############\n","print(\"10 từ đầu tiên trong từ điển:\")\n","i = 0\n","for k, v in module_count_vector.vocabulary_.items():\n","    i += 1\n","    print(i, \": \", (k, v))\n","    if i > 9:\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fe-ty94ZFriu"},"outputs":[],"source":["### Example\n","corpus = [\n","    \"This is the first document.\",\n","    \"This document is the second document.\",\n","    \"And this is the third one.\",\n","    \"Is this the first document?\",\n","]\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(corpus)\n","# vectorizer.get_feature_names_out()\n","\n","for k, v in vectorizer.vocabulary_.items():\n","    i += 1\n","    print(i, \": \", (k, v))\n","    # if i > 10:\n","    #     break\n","\n","\n","print(X.toarray())\n","\n","vectorizer2 = CountVectorizer(analyzer=\"word\", ngram_range=(2, 2))\n","X2 = vectorizer2.fit_transform(corpus)\n","# vectorizer2.get_feature_names_out()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4t4h4KBJG2pW"},"outputs":[],"source":["### bài tập ###\n","# yêu cầu: Tiền xử lý với TfidfVectorizer, in ra 10 từ đầu tiên trong từ điển.\n","# gợi ý: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n","###############\n","# code\n","###############"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wGce90QVHhC3"},"outputs":[],"source":["### bài tập ###\n","# yêu cầu: Tìm ra top 10 từ có giá trị TF-IDF cao nhất.\n","# gợi ý: tự làm\n","###############\n","\n","# code\n","###############"]},{"cell_type":"markdown","metadata":{"id":"r2ojuLvEH3HP"},"source":["## **5. Chia dữ liệu làm 2 phần training và testing**\n","\n","*   Training chiếm 80 % dữ liệu\n","*   Testing chiếm 20 % dữ liệu\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Lh5jpAc_H347"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dữ liệu training (BoW) = (908, 25199) (908,)\n","Dữ liệu testing (BoW) = (227, 25199) (227,)\n","\n","Dữ liệu training (TF-IDF) = (908, 25199) (908,)\n","Dữ liệu testing (TF-IDF) = (227, 25199) (227,)\n","\n","Danh sách nhãn và id tương ứng:  [(0, 'Giải trí'), (1, 'Khoa học - Công nghệ'), (2, 'Kinh tế'), (3, 'Pháp luật'), (4, 'Sức khỏe'), (5, 'Thể thao'), (6, 'Thời sự'), (7, 'Tin khác'), (8, 'Độc giả'), (9, 'Đời sống - Xã hội')]\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","# Chia dữ liệu thành 2 phần sử dụng hàm train_test_split\n","test_size = 0.2\n","# Bow\n","X_train, X_test, y_train, y_test = train_test_split(data_bow, data_train.target, test_size=test_size, random_state=30)\n","# Tf-idf\n","X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(data_tfidf, data_train.target, test_size=test_size, random_state=30)\n","\n","# Hiển thị một số thông tin về dữ liệu\n","print(\"Dữ liệu training (BoW) =\", X_train.shape, y_train.shape)\n","print(\"Dữ liệu testing (BoW) =\", X_test.shape, y_test.shape)\n","\n","print()\n","\n","print(\"Dữ liệu training (TF-IDF) =\", X_train_tfidf.shape, y_train_tfidf.shape)\n","print(\"Dữ liệu testing (TF-IDF) =\", X_test_tfidf.shape, y_test_tfidf.shape)\n","\n","print()\n","\n","print(\"Danh sách nhãn và id tương ứng: \", [(idx, name) for idx, name in enumerate(data_train.target_names)])"]},{"cell_type":"markdown","metadata":{"id":"YPG4asQ2IDul"},"source":["## **6. Training SVM model**\n","\n","\n","Sử dụng thư viện sklearn để xây dựng mô hình:\n","\n",">`svm.SVC(kernel='linear', C=1.0)`: chọn hàm nhân phân tách là linear, tham số C=1.0\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"oghO33KJIM8G"},"outputs":[{"name":"stdout","output_type":"stream","text":["- Training ...\n","- Train size = (908, 25199)\n","- model - train complete\n"]}],"source":["print(\"- Training ...\")\n","print(\"- Train size = {}\".format(X_train.shape))\n","model = svm.SVC(kernel=\"linear\", C=1.0)\n","model.fit(X_train, y_train)\n","print(\"- model - train complete\")"]},{"cell_type":"markdown","metadata":{"id":"xz1hDmztISIJ"},"source":["## **7. Testing SVM model**\n","\n","\n","*   Thực hiện dự đoán nhãn cho từng văn bản trong tập test\n","*   Độ đo đánh giá:\n","> accuracy = tổng số văn bản dự đoán đúng  / tổng số văn bản có trong tập test"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"quoepvC8ITB3"},"outputs":[{"name":"stdout","output_type":"stream","text":["- Testing ...\n","- Acc = 0.7929515418502202\n"]}],"source":["print(\"- Testing ...\")\n","y_pred = model.predict(X_test)\n","print(\"- Acc = {}\".format(accuracy_score(y_test, y_pred)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l3rGJB0WIhEE"},"outputs":[],"source":["### bài tập ###\n","# yêu cầu: Thực hiện lại các bước huấn luận, kiểm thử mô hình với hàm phân tách 'rbf' (radial basis function), hay hàm Gaussian.\n","# gợi ý: tự làm\n","###############\n","# code\n","###############"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZjBBFQmpJlo_"},"outputs":[],"source":["### bài tập ###\n","# yêu cầu: Dự đoán nhãn cho văn bản: \"Mệt mỏi vì hóa đơn tiền điện tăng cao?\n","#                                     Muốn tận hưởng không gian mát lạnh mà không lo tốn kém?\n","#                                     Video này sẽ bật mí cho bạn những bí quyết sử dụng điều hòa Inverter hiệu quả nhất.\n","#                                     Từ cách chọn chế độ, cài đặt nhiệt độ đến bảo dưỡng máy,\n","#                                     tất cả sẽ được giải đáp chi tiết.\n","#                                     Đừng bỏ lỡ cơ hội tiết kiệm hàng triệu đồng mỗi năm!\".\n","#          So sánh kết quả dự đoán của 2 mô hình đã huấn luyện với 2 hàm phân tách \"linear\" và \"rbf\"\n","#          (Mở rộng) Hiển thị Support vector visualization\n","# gợi ý: tự làm\n","###############\n","# code\n","\n","###############"]},{"cell_type":"markdown","metadata":{"id":"aPVMoAdDS1tt"},"source":["## **8. Bài tập bổ sung:**\n","\n",">8.1 Thử nghiệm các tham số\n","\n","- Các tham số với giá trị khác nhau có thể ảnh hưởng để kết quả học\n","- Cần thử nghiệm kỹ lượng để đưa ra kết quả khách quan: tham số C, gamma, kernel.\n","    - Chọn mô hình với bộ tham số cho kết quả tốt nhất\n","- Gợi ý:\n","    - https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n","    - Sử dụng grid search"]},{"cell_type":"markdown","metadata":{"id":"_nj-1OW_TTY0"},"source":["#### **Bài tâp**: Vẽ Learning curve khảo sát Acc của SVM-linear với tham số C thay đổi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rZa1yDwAS7iU"},"outputs":[],"source":["list_C = [0.001, 0.01, 0.1, 1, 5.0, 10.0, 100]\n","list_acc = []\n","title = \"Learning Curves SVM, Linear kernel, change C\"\n","\n","# duyệt qua mảng các giá trị của tham số C\n","for i, C in enumerate(list_C):\n","    # Với từng giá trị C nhận được,\n","    # thực hiện build model và training cross-validate\n","    # vẽ kết quả tìm được lên đồ thị đường.\n","    model = svm.SVC(kernel=\"linear\", C=C)\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    list_acc.append(accuracy_score(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eMZnomM4TbOh"},"outputs":[],"source":["import seaborn as sns\n","\n","fig = sns.lineplot(x=list(range(0, 7)), y=list_acc)\n","fig.set_xticks(range(0, 7))\n","fig.set_xticklabels([0.001, 0.01, 0.1, 1, 5.0, 10.0, 100])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nJbj6N-TTd8L"},"outputs":[],"source":["# hàm sinh id màu\n","def get_cmap(n):\n","    return \"C\" + str(n)\n","\n","\n","# Hàm thực hiện training model, crossvalidate và vẽ lên đồ thị sử dụng mat libplot\n","def plot_learning_curve(estimator, title, label_curve, X, y, ylim=None, cv=None, n_jobs=1, train_sizes=np.linspace(0.1, 1.0, 5), new_plot=False, idx_color=0):\n","    # Khởi tạo bức ảnh mới với thư viện plot lib\n","    if new_plot:\n","        # plt.figure()\n","        plt.title(title)\n","        plt.xlabel(\"Training examples\")\n","        plt.ylabel(\"Accuracy\")\n","        plt.grid()\n","\n","    # chú thích nếu có\n","    if ylim is not None:\n","        plt.ylim(*ylim)\n","\n","    # thực hiện training model, ghi nhận các giá trị trong quá trình training\n","    # cv = số fold cross validate, số phần bộ dữ liệu được chia để thực hiện training testing.\n","    # train_sizes = mảng tỉ lệ, các tỉ lệ được hệ thống chọn làm điểm dừng để thực hiện 1 testing\n","    #  train_sizes = [0.3, 0.5] => hệ thống lấy 30 % dữ liệu để train và thực hiện test, tương tự 50 % ..\n","    # scoring = hàm mục tiêu để đánh giá chất lượng mô hình và vẽ lên đồ thị\n","    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring=\"accuracy\")\n","\n","    # Lấy trung bình cộng các giá trị output của các fold\n","    train_scores_mean = np.mean(train_scores, axis=1)\n","    train_scores_std = np.std(train_scores, axis=1)\n","    test_scores_mean = np.mean(test_scores, axis=1)\n","    test_scores_std = np.std(test_scores, axis=1)\n","\n","    # random 1 màu để vẽ\n","    color = get_cmap(idx_color)\n","\n","    # thực hiện vẽ các giá trị số lên đồ thị với màu vừa được random\n","    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=color)\n","    plt.plot(train_sizes, test_scores_mean, \"o-\", color=color, label=label_curve)\n","\n","    plt.legend(loc=\"best\")\n","    return plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zzM2e028Tfmm"},"outputs":[],"source":["list_C = [0.001, 0.01, 0.1, 1, 5.0, 10.0, 100]\n","# model title\n","title = \"Learning Curves SVM, Linear kernel, change C\"\n","\n","# duyệt qua mảng các giá trị của tham số C\n","for i, C in enumerate(list_C):\n","    # Với từng giá trị C nhận được,\n","    # thực hiện build model và training cross-validate\n","    # vẽ kết quả tìm được lên đồ thị đường.\n","    text_clf = Pipeline(\n","        [\n","            (\"clf\", svm.SVC(kernel=\"linear\", C=C)),  # mô hình svm với tham số C\n","        ]\n","    )\n","\n","    plt = plot_learning_curve(text_clf, title, \"C = %.3f\" % (C), data_preprocessed, data_train.target, (0.0, 1.01), cv=10, n_jobs=-1, idx_color=i, new_plot=i == 0)\n","\n","# lưu hình ảnh ra file\n","# plt.savefig('images/changeC.png', bbox_inches='tight')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SoWSOmO6fg79"},"outputs":[],"source":["### bài tập ###\n","# yêu cầu: Đánh giá sự thay đổi của hàm phân tách ảnh hưởng thế nào đến độ chính xác của mô hình. Vẽ biểu đồ minh họa.\n","# gợi ý: Xét các hàm phân tách được định nghĩa trước trong svm.SVC() ('linear', 'poly', 'rbf')\n","#        Tương tự thay đổi về giá trị C\n","###############\n","# code\n","\n","###############"]},{"cell_type":"markdown","metadata":{"id":"NxnmAbnjTl8k"},"source":["#### **Tunning model**: Sử dụng GridSearchCV để tìm bộ tham số tốt nhất"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"RgSh3SQyTjCO"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n","SVC(C=100, gamma=0.0001)\n","Testing\n","0.8105726872246696\n"]}],"source":["params_grid = {\"C\": [0.001, 0.01, 0.1, 1, 10, 100], \"gamma\": [0.0001, 0.001, 0.01, 0.1], \"kernel\": [\"linear\", \"rbf\", \"poly\"]}\n","\n","model = svm.SVC()\n","# Create the GridSearchCV object\n","best_model = GridSearchCV(model, params_grid, cv=4, n_jobs=-1, scoring=\"accuracy\")\n","\n","# Fit the data with the best possible parameters\n","best_model.fit(X_train, y_train)\n","\n","# Print the best estimator with it's parameters\n","print(best_model.best_params_)\n","print(best_model.best_estimator_)\n","# Test best_model\n","print(\"Testing\")\n","y_pred = best_model.predict(X_test)\n","print(accuracy_score(y_test, y_pred))"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}
